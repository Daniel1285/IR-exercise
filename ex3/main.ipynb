{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-12T16:47:19.001356Z",
     "start_time": "2025-01-12T16:47:18.992004Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T16:42:27.415869Z",
     "start_time": "2025-01-12T16:42:27.406990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PRO_ISRAELI =[ \"cabinet\", \"government\", \"homeland\", \"humanitarian aid\", \"idf\", \"iron dome\",\n",
    "    \"israel\", \"israeli\", \"jerusalem\", \"jewish\", \"knesset\", \"mossad\", \"netanyahu\",\n",
    "    \"occupation\", \"occupied territories\", \"parliament\", \"settlers\", \"tel aviv\",\n",
    "    \"west bank\", \"zionism\", \"zionist entity\", \"zionist regime\", \"zionist state\",\n",
    "    \"security\", \"defense forces\", \"coexistence\", \"peace\", \"innovation\", \"startup nation\",\n",
    "    \"sabra\", \"heritage\", \"aliyah\", \"yom hashoah\", \"yom hazikaron\", \"yom haatzmaut\",\n",
    "    \"negev\", \"ashkelon\", \"ashdod\", \"haifa\", \"eilat\", \"ben gurion\", \"sderot\",\n",
    "    \"technological advancement\", \"diplomacy\", \"jewish agency\", \"menorah\",\n",
    "    \"western wall\", \"temple mount\", \"david's star\", \"dead sea\", \"red sea\",\n",
    "    \"kinneret\", \"masada\", \"hebrew\", \"torah\", \"synagogue\", \"economic growth\",\n",
    "    \"resilience\", \"chutzpah\", \"maccabees\", \"diaspora\", \"el al\", \"hatikvah\"\n",
    "]\n",
    "\n",
    "PRO_PALESTINIAN = [\n",
    "    \"abbas\", \"colonizers\", \"displaced\", \"freedom fighters\", \"gaza\", \"gazans\",\n",
    "    \"hamas\", \"hassan nasrallah\", \"hezbollah\", \"houthis\", \"humanitarian crisis\",\n",
    "    \"intifada\", \"iran\", \"muhammad sinuar\", \"naim qassem\", \"nakba\", \"nukhba\",\n",
    "    \"oppressed\", \"organization\", \"palestine\", \"palestinians\", \"plo\", \"refugees\",\n",
    "    \"resistance\", \"resisters\", \"sinuar\", \"terrorists\", \"tyrants\", \"checkpoint\",\n",
    "    \"apartheid\", \"liberation\", \"sovereignty\", \"right of return\", \"unrwa\",\n",
    "    \"blockade\", \"land day\", \"sheikh jarrah\", \"solidarity\", \"intifada stones\",\n",
    "    \"ceasefire\", \"al quds\", \"naksa\", \"siege\", \"exile\", \"ethnic cleansing\",\n",
    "    \"political prisoners\", \"self-determination\", \"separation wall\", \"war crimes\",\n",
    "    \"genocide\", \"protest\", \"justice\", \"humanitarian assistance\", \"freedom march\",\n",
    "    \"jenin\", \"rafah\", \"khan younis\", \"beit hanoun\", \"hebron\", \"bethlehem\",\n",
    "    \"nablus\", \"ramallah\", \"al-awda\", \"jerusalem\", \"al-naksa\", \"martyr\",\n",
    "    \"international law\", \"un resolution\", \"settler violence\", \"deir yassin\",\n",
    "    \"sabra and shatila\", \"olive trees\", \"revolution\", \"human rights\"\n",
    "]"
   ],
   "id": "951c1c93e62a0752",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T16:42:56.934574Z",
     "start_time": "2025-01-12T16:42:30.071583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Excel file\n",
    "def process_text():\n",
    "  file_path = \"posts_first_targil.xlsx\"\n",
    "  df = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "  # Initialize the new DataFrame\n",
    "  df_sentence = pd.DataFrame(columns=['sheet_name', 'id', 'sentence'])\n",
    "\n",
    "  # Process each sheet in the Excel file\n",
    "  for sheet_name, data in df.items():\n",
    "      for index, row in data.iterrows():\n",
    "          # Combine text based on the sheet\n",
    "          if sheet_name == 'A-J':\n",
    "              combined_text = \" \".join(str(row[col]) for col in ['title', 'sub_title', 'Body Text'] if col in row and pd.notna(row[col]))\n",
    "          else:\n",
    "              combined_text = \" \".join(str(row[col]) for col in ['title', 'Body Text'] if col in row and pd.notna(row[col]))\n",
    "\n",
    "          # Split the combined text into sentences\n",
    "          sentences = [sentence.strip() for sentence in re.split(r'[.!?]', combined_text) if sentence.strip()]\n",
    "\n",
    "          # Append sentences to the new DataFrame\n",
    "          for sentence in sentences:\n",
    "              df_sentence = pd.concat([df_sentence, pd.DataFrame({ 'sheet_name': [sheet_name], 'id': [index], 'sentence': [sentence]})], ignore_index=True)\n",
    "  df_sentence.head()\n",
    "  return df_sentence\n",
    "\n",
    "data = process_text()\n",
    "print(len(data))\n"
   ],
   "id": "4da133f71d26dcb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30125\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T16:42:58.647478Z",
     "start_time": "2025-01-12T16:42:57.021750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_sentences(df, pro_israeli_words, pro_palestinian_words):\n",
    "    extracted = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        doc_id = row['id']\n",
    "\n",
    "        sentence = row['sentence'].strip().lower()\n",
    "        sheet_name = row['sheet_name']\n",
    "        # Check for pro-Israeli and pro-Palestinian keywords\n",
    "        is_pro_israeli = any(word in sentence for word in pro_israeli_words)\n",
    "        is_pro_palestinian = any(word in sentence for word in pro_palestinian_words)\n",
    "\n",
    "        # Determine the type based on keywords\n",
    "        if is_pro_israeli and not is_pro_palestinian:\n",
    "            extracted.append((doc_id,sheet_name, sentence, 'pro-israeli'))\n",
    "        elif is_pro_palestinian and not is_pro_israeli:\n",
    "            extracted.append((doc_id,sheet_name, sentence, 'pro-palestinian'))\n",
    "\n",
    "    return pd.DataFrame(extracted, columns=['id','sheet_name', 'sentence', 'lebal'])\n",
    "\n",
    "data = extract_sentences(data,PRO_ISRAELI,PRO_PALESTINIAN)\n",
    "print(len(data))"
   ],
   "id": "e345233899abb11b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9564\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T16:50:01.671373Z",
     "start_time": "2025-01-12T16:49:57.618838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "def sentiment_models():\n",
    "    model_paths = {\n",
    "        'model1': \"cardiffnlp/twitter-roberta-base-sentiment-latest\",\n",
    "        'model2': \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
    "        'model3': \"cardiffnlp/twitter-xlm-roberta-base-sentiment\",\n",
    "        'model4': \"siebert/sentiment-roberta-large-english\",\n",
    "        'model5': \"lxyuan/distilbert-base-multilingual-cased-sentiments-student\",\n",
    "        'model6': \"finiteautomata/bertweet-base-sentiment-analysis\",\n",
    "        'model7': \"j-hartmann/sentiment-roberta-large-english-3-classes\"\n",
    "    }\n",
    "\n",
    "    sent_models = {}\n",
    "\n",
    "    for name, path in model_paths.items():\n",
    "        try:\n",
    "            if name == 'model3':\n",
    "                # Explicitly handle model3 with slow tokenizer if necessary\n",
    "                tokenizer = AutoTokenizer.from_pretrained(path, use_fast=False)  # Use slow tokenizer for SentencePiece\n",
    "                model = AutoModelForSequenceClassification.from_pretrained(path)\n",
    "                sent_models[name] = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "            else:\n",
    "                # Default pipeline loading for other models\n",
    "                sent_models[name] = pipeline(\"sentiment-analysis\", model=path, tokenizer=path)\n",
    "            print(f\"{name}: Loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"{name}: Failed to load - {e}\")\n",
    "            sent_models[name] = None\n",
    "\n",
    "    return sent_models\n",
    "\n",
    "# Initialize and test models\n",
    "models = sentiment_models()\n"
   ],
   "id": "656ab01313270886",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1: Loaded successfully\n",
      "model2: Loaded successfully\n",
      "model3: Failed to load - Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']\n",
      "model4: Loaded successfully\n",
      "model5: Loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model6: Loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at j-hartmann/sentiment-roberta-large-english-3-classes were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model7: Loaded successfully\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def map_sentiment_to_context(sentiment_label, score, sentence_context):\n",
    "    \"\"\"Map sentiment label to pro-Israeli/pro-Palestinian context.\"\"\"\n",
    "\n",
    "    # Normalize sentiment label\n",
    "    sentiment = sentiment_label.lower()\n",
    "\n",
    "    # Neutral sentiment handling\n",
    "    if 'neutral' in sentiment:\n",
    "        return 'NEUTRAL'\n",
    "\n",
    "    # Map sentiment based on sentence context\n",
    "    if sentence_context == 'pro-israeli':\n",
    "        return 'POS' if sentiment in ['positive', 'pos'] else 'NEG'\n",
    "    elif sentence_context == 'pro-palestinian':\n",
    "        return 'POS' if sentiment in ['positive', 'pos'] else 'NEG'\n",
    "\n",
    "    # Default to NEUTRAL if no match\n",
    "    return 'NEUTRAL'\n",
    "\n",
    "\n",
    "def evaluate_sentence_with_models(sentence, context_type, models, tokenizer_name=\"bert-base-uncased\"):\n",
    "    \"\"\"\n",
    "    Evaluate a sentence using multiple models, splitting it into chunks if necessary.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence to evaluate.\n",
    "        context_type (str): The context type (e.g., 'pro-israeli', 'pro-palestinian').\n",
    "        models (dict): A dictionary of model names and their instances.\n",
    "        tokenizer_name (str): The tokenizer to use for token length calculation.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of model results including scores and labels.\n",
    "    \"\"\"\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "    # Tokenize the sentence and check its length\n",
    "    tokenized_sentence = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    if len(tokenized_sentence) <= 512:\n",
    "        # Sentence fits within token limits\n",
    "        return _evaluate_single_sentence(sentence, context_type, models)\n",
    "    else:\n",
    "        # Split the sentence into smaller chunks\n",
    "        chunks = _split_into_chunks(sentence, tokenizer, max_length=512)\n",
    "        aggregated_results = {}\n",
    "\n",
    "        for chunk in chunks:\n",
    "            chunk_results = _evaluate_single_sentence(chunk, context_type, models)\n",
    "            for key, value in chunk_results.items():\n",
    "                if key in aggregated_results:\n",
    "                    aggregated_results[key].append(value)\n",
    "                else:\n",
    "                    aggregated_results[key] = [value]\n",
    "\n",
    "        # Aggregate results across chunks\n",
    "        return _aggregate_chunk_results(aggregated_results)\n",
    "\n",
    "\n",
    "def _evaluate_single_sentence(sentence, context_type, models):\n",
    "    \"\"\"\n",
    "    Evaluate a single sentence using multiple models.\n",
    "    \"\"\"\n",
    "    evaluation_results = {}\n",
    "\n",
    "    for model_name, model_instance in models.items():\n",
    "        try:\n",
    "            prediction = model_instance(sentence)[0]\n",
    "            evaluation_results[f\"{model_name}_score\"] = prediction['score']\n",
    "            evaluation_results[f\"{model_name}_label\"] = map_sentiment_to_context(\n",
    "                prediction['label'], prediction['score'], context_type\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error with model '{model_name}' for sentence: '{sentence[:50]}...' Error: {e}\")\n",
    "            evaluation_results[f\"{model_name}_score\"] = None\n",
    "            evaluation_results[f\"{model_name}_label\"] = None\n",
    "\n",
    "    return evaluation_results\n",
    "\n",
    "\n",
    "def _split_into_chunks(sentence, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Split a sentence into chunks that fit within the token limit.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The sentence to split.\n",
    "        tokenizer: The tokenizer instance.\n",
    "        max_length (int): The maximum number of tokens per chunk.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of sentence chunks.\n",
    "    \"\"\"\n",
    "    words = sentence.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        # Add word to the current chunk and check its token length\n",
    "        current_chunk.append(word)\n",
    "        if len(tokenizer.encode(\" \".join(current_chunk), add_special_tokens=True)) > max_length:\n",
    "            # Remove the last word and finalize the current chunk\n",
    "            current_chunk.pop()\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = [word]\n",
    "\n",
    "    # Add the final chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def _aggregate_chunk_results(results):\n",
    "    \"\"\"\n",
    "    Aggregate results across multiple chunks by averaging scores and determining majority labels.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "\n",
    "    for key, values in results.items():\n",
    "        if '_score' in key:\n",
    "            # Average scores\n",
    "            aggregated[key] = sum(values) / len(values)\n",
    "        elif '_label' in key:\n",
    "            # Majority label\n",
    "            aggregated[key] = max(set(values), key=values.count)\n",
    "\n",
    "    return aggregated\n",
    "\n",
    "def determine_majority_sentiment(row):\n",
    "    \"\"\"Determine the majority sentiment label across multiple models.\"\"\"\n",
    "    sentiment_labels = [value for key, value in row.items() if '_label' in key and value is not None]\n",
    "\n",
    "    if not sentiment_labels:\n",
    "        return 'UNKNOWN'\n",
    "\n",
    "    # Determine majority label\n",
    "    majority_label = max(set(sentiment_labels), key=sentiment_labels.count)\n",
    "    return majority_label"
   ],
   "id": "d3bc16947f5f8bf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Process each sentence\n",
    "results = []\n",
    "for idx, row in tqdm(data.iterrows(), total=len(data)):\n",
    "    result = {\n",
    "        'newspaper': row['sheet_name'].split('_')[0],\n",
    "        'article_id': row['id'],\n",
    "        'sentence': row['sentence'],\n",
    "        'type': row['lebal']\n",
    "    }\n",
    "\n",
    "    # Add model predictions\n",
    "    result.update(evaluate_sentence_with_models(row['sentence'], row['lebal'], models))\n",
    "\n",
    "    # Add to results\n",
    "    results.append(result)\n",
    "\n",
    "# Create final DataFrame\n",
    "output_df = pd.DataFrame(results)\n",
    "\n",
    "# Add majority decision\n",
    "output_df['majority_decision'] = output_df.apply(determine_majority_sentiment, axis=1)\n",
    "\n",
    "# Calculate average score for majority decision\n",
    "score_columns = [col for col in output_df.columns if '_score' in col]\n",
    "output_df['avg_majority_score'] = output_df[score_columns].mean(axis=1)\n",
    "# Save to Excel\n",
    "output_df.to_excel('sentiment_results.xlsx', index=False)\n"
   ],
   "id": "13ec1be5f7dc85b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
